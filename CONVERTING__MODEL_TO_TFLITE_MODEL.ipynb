{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CONVERTING_ MODEL TO TFLITE MODEL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAGUn8cKK_ql"
      },
      "source": [
        "# CONVERTING TRAINED SSD MODEL TO TFLITE MODEL "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ6xQI2ZLMoC"
      },
      "source": [
        "# **1) INSTALL tf-nightly** \n",
        "TFLite converter works better with tf-nightly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGZvPbhZ_2n0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1397d2e-309d-49f5-91f3-6abb8422bd37"
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.10.0.dev20220427-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (503.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 503.2 MB 3.9 kB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly~=2.10.0.dev\n",
            "  Downloading tf_estimator_nightly-2.10.0.dev2022050708-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (4.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.44.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (21.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.20.1)\n",
            "Collecting keras-nightly~=2.10.0.dev\n",
            "  Downloading keras_nightly-2.10.0.dev2022050807-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.14.0)\n",
            "Collecting tb-nightly~=2.9.0.a\n",
            "  Downloading tb_nightly-2.9.0a20220502-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly) (3.0.8)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-nightly, gast, flatbuffers, tf-nightly\n",
            "  Attempting uninstall: tf-estimator-nightly\n",
            "    Found existing installation: tf-estimator-nightly 2.8.0.dev2021122109\n",
            "    Uninstalling tf-estimator-nightly-2.8.0.dev2021122109:\n",
            "      Successfully uninstalled tf-estimator-nightly-2.8.0.dev2021122109\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, but you have tf-estimator-nightly 2.10.0.dev2022050708 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-nightly-2.10.0.dev2022050807 tb-nightly-2.9.0a20220502 tf-estimator-nightly-2.10.0.dev2022050708 tf-nightly-2.10.0.dev20220427\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **NOTE:** Once you install tf-nightly and restart runtime, make sure to run steps 5 & 6 again to mount the drive and install TensorFlow object detection api again"
      ],
      "metadata": {
        "id": "0InEJ7h9wU1c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9I6sd5yyIqT"
      },
      "source": [
        "# **2) Export SSD TFLite graph**\n",
        "\n",
        "Current working directory is /content/models/research/object_detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCepCTumuAPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c38c29-7464-4fa3-9617-4360c624f769"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "!python export_tflite_graph_tf2.py --pipeline_config_path /content/gdrive/MyDrive/customTF2/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --trained_checkpoint_dir /mydrive/customTF2/training --output_directory /mydrive/customTF2/data/tflite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/models/research/object_detection'\n",
            "/content/gdrive/My Drive/customTF2/data/models/research\n",
            "python3: can't open file 'export_tflite_graph_tf2.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0A5J5o5EQxi"
      },
      "source": [
        "# **3) Convert TF saved model to TFLite model**\n",
        "\n",
        "Current working directory is /mydrive/customTF2/data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90O8Qn4-b69v"
      },
      "source": [
        "## Check input and output tensor names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dw0uZHmCtuL"
      },
      "source": [
        "!saved_model_cli show --dir /mydrive/customTF2/data/tflite/saved_model --tag_set serve --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ay_uDcUNv-H"
      },
      "source": [
        "## Converting to TFlite:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe_ohR_sBcIJ"
      },
      "source": [
        "Use either Method (a) or Method (b). Read more about these in the [blog](https://techzizou007.medium.com/build-android-app-for-custom-object-detection-tf-2-x-53904a08cfa2#6cac)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### METHOD (a) Using command-line tool `tflite_convert`- (Basic model conversion)"
      ],
      "metadata": {
        "id": "Kbxa29fFyAtm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUb6Rwk_MKE1"
      },
      "source": [
        "# The default inference type is Floating-point.\n",
        "%cd /mydrive/customTF2/data/\n",
        "\n",
        "!tflite_convert --saved_model_dir=tflite/saved_model --output_file=tflite/detect.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### METHOD (b) Using Python API - (For advanced model conversion with optimizations etc)"
      ],
      "metadata": {
        "id": "SHIqP635yWxd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEPCx6lf__ey"
      },
      "source": [
        "%cd /mydrive/customTF2/data/\n",
        "\n",
        "#'''********************************\n",
        "#   FOR FLOATING-POINT INFERENCE\n",
        "#*********************************'''\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "saved_model_dir = '/mydrive/customTF2/data/tflite/saved_model'\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "open(\"/mydrive/customTF2/data/tflite/detect.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "\n",
        "#'''**************************************************\n",
        "#  FOR FLOATING-POINT INFERENCE WITH OPTIMIZATIONS\n",
        "#***************************************************'''\n",
        "\n",
        "# import tensorflow as tf\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model('/mydrive/customTF2/data/tflite/saved_model',signature_keys=['serving_default'])\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.experimental_new_converter = True\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,  \n",
        "#                                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "# tflite_model = converter.convert()\n",
        "\n",
        "# with tf.io.gfile.GFile('/mydrive/customTF2/data/tflite/detect.tflite', 'wb') as f:\n",
        "#   f.write(tflite_model)\n",
        "\n",
        "\n",
        "#'''**********************************\n",
        "#    FOR DYNAMIC RANGE QUANTIZATION \n",
        "#*************************************\n",
        "# The model is now a bit smaller with quantized weights, but other variable data is still in float format.'''\n",
        "\n",
        "# import tensorflow as tf\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model('/mydrive/customTF2/data/tflite/saved_model',signature_keys=['serving_default'])\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# tflite_quant_model = converter.convert()\n",
        "\n",
        "# with tf.io.gfile.GFile('/mydrive/customTF2/data/tflite/detect.tflite', 'wb') as f:\n",
        "#   f.write(tflite_quant_model)\n",
        "\n",
        "\n",
        "#'''*************************************************************\n",
        "#    FOR FLOAT FALLBACK QUANTIZATION WITH DEFAULT OPTMIZATIONS \n",
        "#****************************************************************\n",
        "#Now all weights and variable data are quantized, and the model is significantly smaller compared to the original TensorFlow Lite model.\n",
        "#However, to maintain compatibility with applications that traditionally use float model input and output tensors, \n",
        "#the TensorFlow Lite Converter leaves the model input and output tensors in float'''\n",
        "\n",
        "# def representative_dataset():\n",
        "#     for _ in range(100):\n",
        "#       data = np.random.rand(1, 320, 320, 3)\n",
        "#       yield [data.astype(np.float32)]\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# tflite_model_quant = converter.convert()\n",
        "\n",
        "\n",
        "#'''*********************************\n",
        "#   FOR FULL INTEGER QUANTIZATION\n",
        "#************************************\n",
        "# The internal quantization remains the same as previous float fallback quantization method, \n",
        "# but you can see the input and output tensors here are also now integer format'''\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "# saved_model_dir = '/mydrive/customTF2/data/tflite/saved_model'\n",
        "\n",
        "# def representative_dataset():\n",
        "#     for _ in range(100):\n",
        "#       data = np.random.rand(1, 320, 320, 3)\n",
        "#       yield [data.astype(np.float32)]\n",
        "\n",
        "# converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.representative_dataset = representative_dataset\n",
        "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# converter.inference_input_type = tf.uint8  \n",
        "# converter.inference_output_type = tf.uint8 \n",
        "# tflite_quant_model_full_int = converter.convert()\n",
        "\n",
        "# with open('detect.tflite', 'wb') as f:\n",
        "#   f.write(tflite_quant_model_full_int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read more about post-training quantization [here](https://medium.com/r/?url=https%3A%2F%2Fwww.tensorflow.org%2Flite%2Fperformance%2Fpost_training_quantization). \n",
        "You can also read about these in [this](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb#scrollTo=wYd6NxD03yjB) colab notebook."
      ],
      "metadata": {
        "id": "Z9r11Cw3noi5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vohoHMVU9Agr"
      },
      "source": [
        "# **4) Create TFLite metadata**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTbqhUlAGab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cf0ead-eff7-4392-9711-477848bdeb58"
      },
      "source": [
        "pip install tflite_support_nightly"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite_support_nightly\n",
            "  Downloading tflite_support_nightly-0.3.0.dev20220507-cp37-cp37m-manylinux2014_x86_64.whl (42.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from tflite_support_nightly) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tflite_support_nightly) (1.12)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite_support_nightly) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.18.0 in /usr/local/lib/python3.7/dist-packages (from tflite_support_nightly) (3.20.1)\n",
            "Collecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.4-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.0->tflite_support_nightly) (1.15.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice>=0.4.4->tflite_support_nightly) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support_nightly) (2.21)\n",
            "Installing collected packages: sounddevice, pybind11, tflite-support-nightly\n",
            "Successfully installed pybind11-2.9.2 sounddevice-0.4.4 tflite-support-nightly-0.3.0.dev20220507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJNFJWctYdIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a51d4f-b3e5-4dd7-e996-cb469efcda33"
      },
      "source": [
        "%cd /mydrive/customTF2/data/\n",
        "%cd tflite/\n",
        "!mkdir tflite_with_metadata\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/customTF2/data\n",
            "/content/gdrive/My Drive/customTF2/data/tflite\n",
            "mkdir: cannot create directory ‘tflite_with_metadata’: File exists\n",
            "/content/gdrive/My Drive/customTF2/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a ***labelmap.txt*** file with the names of the classes written in each line inside the ***data*** folder as shown in the blog at step 20. "
      ],
      "metadata": {
        "id": "Zk0qf7O00IwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally run the following cell to create the ***detect.tflite*** model with metadata attached to it.\n",
        "\n",
        "Current working directory is /mydrive/customTF2/data/\n"
      ],
      "metadata": {
        "id": "X312ioM91A_E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvqgQJtGuHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5c7c24-4485-4413-9806-e7ec2511b8eb"
      },
      "source": [
        "%cd /mydrive/customTF2/data/\n",
        "\n",
        "# Attach Metadata to TFLite\n",
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils\n",
        "from tflite_support import metadata\n",
        "import flatbuffers\n",
        "import os\n",
        "from tensorflow_lite_support.metadata import metadata_schema_py_generated as _metadata_fb\n",
        "from tensorflow_lite_support.metadata.python import metadata as _metadata\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_info\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import metadata_writer\n",
        "from tensorflow_lite_support.metadata.python.metadata_writers import writer_utils\n",
        "\n",
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        "\n",
        "_MODEL_PATH = \"/mydrive/customTF2/data/tflite/detect.tflite\"\n",
        "_LABEL_FILE = \"/mydrive/customTF2/data/labelmap.txt\"\n",
        "_SAVE_TO_PATH = \"/mydrive/customTF2/data/tflite/tflite_with_metadata/detect.tflite\"\n",
        "\n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [127.5], [127.5], [_LABEL_FILE])\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)\n",
        "\n",
        "# Verify the populated metadata and associated files.\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(_SAVE_TO_PATH)\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "print(\"Associated file(s) populated:\")\n",
        "print(displayer.get_packed_associated_file_list())\n",
        "\n",
        "model_meta = _metadata_fb.ModelMetadataT()\n",
        "model_meta.name = \"SSD_Detector\"\n",
        "model_meta.description = (\n",
        "    \"Identify which of a known set of objects might be present and provide \"\n",
        "    \"information about their positions within the given image or a video \"\n",
        "    \"stream.\")\n",
        "\n",
        "# Creates input info.\n",
        "input_meta = _metadata_fb.TensorMetadataT()\n",
        "input_meta.name = \"image\"\n",
        "input_meta.content = _metadata_fb.ContentT()\n",
        "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
        "input_meta.content.contentProperties.colorSpace = (\n",
        "    _metadata_fb.ColorSpaceType.RGB)\n",
        "input_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.ImageProperties)\n",
        "input_normalization = _metadata_fb.ProcessUnitT()\n",
        "input_normalization.optionsType = (\n",
        "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
        "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
        "input_normalization.options.mean = [127.5]\n",
        "input_normalization.options.std = [127.5]\n",
        "input_meta.processUnits = [input_normalization]\n",
        "input_stats = _metadata_fb.StatsT()\n",
        "input_stats.max = [255]\n",
        "input_stats.min = [0]\n",
        "input_meta.stats = input_stats\n",
        "\n",
        "# Creates outputs info.\n",
        "output_location_meta = _metadata_fb.TensorMetadataT()\n",
        "output_location_meta.name = \"location\"\n",
        "output_location_meta.description = \"The locations of the detected boxes.\"\n",
        "output_location_meta.content = _metadata_fb.ContentT()\n",
        "output_location_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.BoundingBoxProperties)\n",
        "output_location_meta.content.contentProperties = (\n",
        "    _metadata_fb.BoundingBoxPropertiesT())\n",
        "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
        "output_location_meta.content.contentProperties.type = (\n",
        "    _metadata_fb.BoundingBoxType.BOUNDARIES)\n",
        "output_location_meta.content.contentProperties.coordinateType = (\n",
        "    _metadata_fb.CoordinateType.RATIO)\n",
        "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_location_meta.content.range.min = 2\n",
        "output_location_meta.content.range.max = 2\n",
        "\n",
        "output_class_meta = _metadata_fb.TensorMetadataT()\n",
        "output_class_meta.name = \"category\"\n",
        "output_class_meta.description = \"The categories of the detected boxes.\"\n",
        "output_class_meta.content = _metadata_fb.ContentT()\n",
        "output_class_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_class_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_class_meta.content.range.min = 2\n",
        "output_class_meta.content.range.max = 2\n",
        "label_file = _metadata_fb.AssociatedFileT()\n",
        "label_file.name = os.path.basename(\"labelmap.txt\")\n",
        "label_file.description = \"Label of objects that this model can recognize.\"\n",
        "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
        "output_class_meta.associatedFiles = [label_file]\n",
        "\n",
        "output_score_meta = _metadata_fb.TensorMetadataT()\n",
        "output_score_meta.name = \"score\"\n",
        "output_score_meta.description = \"The scores of the detected boxes.\"\n",
        "output_score_meta.content = _metadata_fb.ContentT()\n",
        "output_score_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_score_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
        "output_score_meta.content.range.min = 2\n",
        "output_score_meta.content.range.max = 2\n",
        "\n",
        "output_number_meta = _metadata_fb.TensorMetadataT()\n",
        "output_number_meta.name = \"number of detections\"\n",
        "output_number_meta.description = \"The number of the detected boxes.\"\n",
        "output_number_meta.content = _metadata_fb.ContentT()\n",
        "output_number_meta.content.contentPropertiesType = (\n",
        "    _metadata_fb.ContentProperties.FeatureProperties)\n",
        "output_number_meta.content.contentProperties = (\n",
        "    _metadata_fb.FeaturePropertiesT())\n",
        "\n",
        "# Creates subgraph info.\n",
        "group = _metadata_fb.TensorGroupT()\n",
        "group.name = \"detection result\"\n",
        "group.tensorNames = [\n",
        "    output_location_meta.name, output_class_meta.name,\n",
        "    output_score_meta.name\n",
        "]\n",
        "subgraph = _metadata_fb.SubGraphMetadataT()\n",
        "subgraph.inputTensorMetadata = [input_meta]\n",
        "subgraph.outputTensorMetadata = [\n",
        "    output_location_meta, output_class_meta, output_score_meta,\n",
        "    output_number_meta\n",
        "]\n",
        "subgraph.outputTensorGroups = [group]\n",
        "model_meta.subgraphMetadata = [subgraph]\n",
        "\n",
        "b = flatbuffers.Builder(0)\n",
        "b.Finish(\n",
        "    model_meta.Pack(b),\n",
        "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
        "metadata_buf = b.Output()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/customTF2/data\n",
            "Metadata populated:\n",
            "{\n",
            "  \"name\": \"ObjectDetector\",\n",
            "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
            "  \"subgraph_metadata\": [\n",
            "    {\n",
            "      \"input_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"image\",\n",
            "          \"description\": \"Input image to be detected.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"ImageProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"color_space\": \"RGB\"\n",
            "            }\n",
            "          },\n",
            "          \"process_units\": [\n",
            "            {\n",
            "              \"options_type\": \"NormalizationOptions\",\n",
            "              \"options\": {\n",
            "                \"mean\": [\n",
            "                  127.5\n",
            "                ],\n",
            "                \"std\": [\n",
            "                  127.5\n",
            "                ]\n",
            "              }\n",
            "            }\n",
            "          ],\n",
            "          \"stats\": {\n",
            "            \"max\": [\n",
            "              1.0\n",
            "            ],\n",
            "            \"min\": [\n",
            "              -1.0\n",
            "            ]\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"score\",\n",
            "          \"description\": \"The scores of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"location\",\n",
            "          \"description\": \"The locations of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"index\": [\n",
            "                1,\n",
            "                0,\n",
            "                3,\n",
            "                2\n",
            "              ],\n",
            "              \"type\": \"BOUNDARIES\"\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"number of detections\",\n",
            "          \"description\": \"The number of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"category\",\n",
            "          \"description\": \"The categories of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          },\n",
            "          \"associated_files\": [\n",
            "            {\n",
            "              \"name\": \"labelmap.txt\",\n",
            "              \"description\": \"Labels for categories that the model can recognize.\",\n",
            "              \"type\": \"TENSOR_VALUE_LABELS\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_groups\": [\n",
            "        {\n",
            "          \"name\": \"detection_result\",\n",
            "          \"tensor_names\": [\n",
            "            \"location\",\n",
            "            \"category\",\n",
            "            \"score\"\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"min_parser_version\": \"1.2.0\"\n",
            "}\n",
            "\n",
            "Associated file(s) populated:\n",
            "['labelmap.txt']\n"
          ]
        }
      ]
    }
  ]
}